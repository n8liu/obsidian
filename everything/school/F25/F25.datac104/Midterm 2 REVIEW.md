analyze readings 2.4, 2.5, 2.6 with focus analysis on key terms and explain the main purpose of the reading in a few sentences so that I can understand the reading basic concept
## Week 5
### Lecture 1.11 & 1.12 → datafied future with ai
- 1.11:
	- datafied future where people suggest how things will be going and compel people to bring it to be true (performative)
	- futuring → how the future is going to look based on today
- 1.12:
	- ai futures into 3 categories: ai dominates, ai fuses with us, and ai becomes our companions
	- AGI will eventually lead to human extinction

### Mireille **Hildebrandt** → smart environment
- the world converted into machine-readable data points where patterns are recognized and personalized (data-driven agency)
- smart environments that influence how we interact directly with our lives and impact our choices based on “best-case scenarios”. this results in human lives being less unique and more dependent
### **Ursula** K. Le Guin → the carrier bag theory
- Carrier Bag Theory → shifts focus from the weapon a carrier bag as one of the most important cultural devices invented. shifts away from violence historically
- technology should be viewed as less tragic as technology is viewed as weapons of domination (spear narrative)
## Week 6
### Lecture 2.1, 2.2, & 2.3 → technology intertwined with human work
- 2.1:
	- decision-making was co-produced with nudging, where nudging is the concept of altering peoples behaviors in predictable ways which shapes citizens actions by nudging. 
	- the influence of technology and humans result in both being intertwined by each other which is the concept of cyborg.
- 2.2: 
	- identity is intertwined with technology
	- performativity is how the world is built around being a classification, which changes how people may perceive themselves when put into new boxes (looping effect → being put into new boxes after new defining themes)
- 2.3:
	- how human and non-human objects interact instead of being inherently political stated by langdon winner (Actor-Network Theory)
	- Delegation → shifting human agency to be replaced by technology
	- Translation → non-human takes on human work

### Karen Yeung → nudging
- nudge → choice architecture using predictive analytics that alters people behavior which usually exploits cognitive weakness
- hypernudge → nudging but more involved networkly, dynamic, and pervasive. mechanism of control and personalized choice based on data profile and trends.
- hypernudge very similar to surveillance capitalism 
- black boxes which is lack of transparency, failure to consent, and unethical concept of big data

### Ian Hacking → the looping effect
- The Looping Effect → individual subject to classification are moving targets due to new classification where they would be considered not the same as before
- Sense A: before diagnosis
- Sense B: way to be oneself and these classifications are just characteristics and not self-defining
- bringing new kinds of people into being and changing the characteristics of those they study

### Bruno Latour → artifacts
- delegation/translation → shifts human actions, values, and ethics onto nonhuman artifacts or program of actions
- prescription where no human is relentlessly moral as a machine
- missing masses are the technical objects that help structure morality and society
- society and technology are not separate but a collective thing

## Week 7
### Lecture 2.4, 2.5, & 2.6 → surveillance as invasion of privacy
- 2.4:
	- the concept of surveillance as a system of seeing, knowing, and power for constructing social order or emphasizes surveillance as the datafied world
	- examples include the panopticon or singapore/north korea
	- orwell → control by an all-powerful big brother
	- panopticon → continuous exposure to observation and self-judgment
	- differential exposure on how surveillance controls certain people or manipulates others
- 2.5:
	- right to be let alone or “Right to Privacy” → the concept of US privacy
	- the introduction of how computerized worlds would historically change the fair information practices
	- Privacy Act of 1974: publics concern over government information holdings and events
	- Privacy Paradigm → focused on personal information over collective impact which 
- 2.6:
	- the reliance of ToS and privacy policies
	- Contextual Integrity (CI)Theory → as an alternative model that shifts the focus of individual control over Personal Identifiable Information. defines privacy as the integrity of a context that must be respected for people to feel secure which is the flow of expected information but if breached is an invasion of privacy

### Gaby Del Valle → the US-Mexico border
- surveillance across the US-Mexico border where it has the highest security and usage of technology
- prevention through deterrence where security is super advanced it pushes people away from the main entrance and towards more dangerous areas of the desert which increases death
- instead of putting the money into technology but into more resources for better regulation

### Lowry Pressly → the right to oblivion
- limits to the knowable for a healthy human life
- the ideology of information where privacy is about controlling or protecting information
- oblivion is defined as a form of obscurity that does not conceal definite information. related to forgetting or not knowing results in more freedom
- where privacy concerns leads to anxiety, which includes the protection of oblivion as a state of not knowing
- the idea of if no information is collected or prevention of data creation
- oblivion recognizes that if their is a need for privacy than data is collected for a datafied reason and already has influence in behavior or the real world

### Nathan Malkin → contextual integrity
- contextual integrity is a privacy model that provides a structure for understanding privacy violations. 
	1. appropriate flow of personal information → shared from one person consensually but if shared with others breaks flow
	2. information flow → contextual information is not violated
	3. five parameters of contextual norms → data type, data subject, sender, recipient, and transmission principle
	4. ethical legitimacy of flows → the benefits of a new flow such as benefiting the larger population rather than ulterior motives outweighs privacy rights
- emphasizes accounting for the complete context noting that even slight changes can violate expectations
- overall helps analyze privacy violations, ethical legitimacy of new technologies, and moves beyond simple consent
- CI is about making sure information stays where it belongs, according to the rules of that specific situation.
- CI is too reliant on context and usually never satisfactory

## Week 8
### Lecture 2.7, 2.8, & 2.9 → open science
- 2.7:
	- reproducibility states how science needs to be replicable so that it can be proven
	- P-hacking → data dredging where publishers bend p-values in their favor
	- Falsificationism → the concept of making a scientific theory needs to be able to be proved wrong
- 2.8:
	- open science → making science open to public so more people can work on it where people who do not have resources can help advance faster
	- limitations of open science → lack formal structure, data accessibility is an invasion of privacy is private research, and could be political in already structures of power and inequality.
- 2.9:
	- democracy depends on experts to support their ideas
	- democracy depends on experts properly managing their relationships with the public through careful communication and by recognizing where the public might meaningfully contribute to scientific knowledge production

### Collins and Pinch → radioactive sheep
- Chernobyl nuclear incident where sheep farmers trusted their entire livestock to scientific practice.
- Chernobyl incident where radioactive material were rained into the livestock of the UK sheep, but scientists did not consider other sources from nearby deposits or historical context
- farmers lost faith in scientific expertise as this causes delay in sales due to results of the radioactive material
- farmers believed in a political cover-up under political pressure and scientists did not consider farmers expertise and solely trusted themselves

### Denisse Alejandra → open science by feminist
- Open and Collaborative Science in Development Network (OCSDNet) → addresses to help design inclusive infrastructures and practices that redress exclusion and foster meaningful participation
- OCSDNet making open science more productive, efficient, and competitive science
- where open science is not solely positive and does not protect information due to fear of political persecution
- inclusive infrastructure as tools or a platform that allow multiple forms of participation amongst diverse background
- where OCSDNet focuses on relationships and people rather than technology

### Thomas Kuhn → science today vs historically
- textbook image of science is persuasive and pedagogic, where the textbook is absolute and follows facts, laws, and theories
- science today and science historically are developed differently, as today is more about research and professional education required and historically more about self discovery and legitimate
- A new theory is rarely just an increment; its assimilation requires the reconstruction of prior theory and the re-evaluation of prior fact
- Thomas S. Kuhn argues that the traditional view, derived from textbooks and "finished scientific achievements," portrays science as an incremental, cumulative process

## Week 9
### Lecture 3.1, 3.2, & 3.3 → silicon valley
- 3.1:
	- silicon valley started from Stanford university and con the name due to the semiconductor industry
	- breaking down how Silicon Valley started where the reading often stated how the success story from military, underlying network connections, and economic forces.
- 3.2:
	- Silicon Valley is a product of financial dynamics through technological breakthroughs
	- Venture Capital → investor backed startups with expectation of making back money through IPOs. this is also known in risk capital
	- venture capitals work because venture capitals rapid growth even if losing money where software is extremely fast growing and usually have high-growth and dominating the market
	- Silicon Valley and Venture Capitals are both involved in political and military growth in mainly exponential growth in economic and military value
- 3.3:
	- The core purpose of this lecture is to challenge the perception of technology and data as "clean" by exposing the material basis, toxicity, and environmental consequences of datafication
	- challenge the perception of technology and data as clean but environmentally impactful where one 8-inch silicon wafer includes 27 lbs of chemicals, thousands of gases, and thousands of gallons of ultrapure water
	- TCA contamination in SJ 1982 where toxic solvent from microchips were inside the neighborhoods drinking water
	- from mining, pollution, water and energy consumption results in environmental justice for all of people.

### Eisenhower’s Speech → military spending in companies
- Dwight Eisenhower’s farewell speech expressed concerned about companies that sough commercial gain through defense spending
- addressed the American people rather than Congress that the military-industrial complex has potential for disastrous and misplaced power
- defense spending should not be based on a companies seeking commercial gain

### Malcom Harris → The Silicon Valley Loop
- successful companies needed to "Go big fast, keep labor and fixed capital costs low, time your exit"
- The Silicon Valley Loop → argues that the tech industry operates in a enormous capital flood of money-losing, rapid-scaling companies, which are all driven by the belief of high growth is mandatory
- "Go big fast, keep labor and fixed capital costs low, time your exit" which is a philosophy inspired by other founders
-  This loop results in platforms that sacrifice labor protections for scaling and are compelled to burn billions of dollars to hold out for a monopoly position, perpetuating a fundamentally speculative economic structure

### Kate Crawford & Vladan Joler → anatomy of AI systems
- Amazon Echo/Alexa as an example of a large-scale AI system
- three intertwined extractive processes across the device’s lifecycle
	1. material resources → non-renewable elements like lithium which are harvested under hazardous conditions
	2. human labor → exploitation and low-paid workers in low-wage countries mainly children or unpaid 
	3. data → to train neural networks (representation of black box)
- Anatomy of AI systems stems from exploitation and nationwide network of unethical accumulation of labor and resources. which all conclude to accumulation of immense wealth
## Week 10
### Lecture 3.4, 3.5, & 3.6 → data as capitalism
- 3.4:
	- explores how data generate value within a framework of capitalism
	- capitalism is seen a major driver of datafication, defined as a the sociotechnical process of turning land, labor, and technologies into income-generating investment opportunities
	- data imperative where data can be created and accumulated into capitalism
	- labor is key in capitalism to generate value
	- commodities to exchange value rather than their direct use value, where data is often positioned as a commodity
- 3.5:
	- automation was not solely about efficiency but was fundamentally tied to creating and disciplining a new labor force → machines are used to create more labor
	- automation in terms of AGI
	- This technology also serves to de-skill and devalue labor, making workers more homogeneous and easier to fire, thus increasing the available labor pool and creating cycles of unemployment.
	- Luddites → textile workers revolted by destroying expensive machines that regulated and controlled tempo of labor which made work dangerous and workers expendable
- 3.6:
	- rise of the service sector and the gig economy which is the central concept of platform economy to manage, organize, and extract value from labor through digital platforms
	- the gig economy or short-term work avoid legal requirements like benefits or protections in-order to make labor more flexible
	- jobs have moved away from manufacturing to labor-intensive service sectors like food-services, healthcare, and delivery etc
	- invisible labor or undervalued or unpaid labor which is hidden labor that help develop the datafied world
	- microlabor which offer humans as a service for data cleaning. labeling, and identifying objects which are hard to calculate wages
	- Digital platforms utilize data-driven and algorithmic management to cut costs, employing pervasive surveillance, rating systems, and gamification to monitor and extract value from labor

### Louis Hyman → exploitation of human labor
- The main purpose of the source is to critically analyze and expose the human cost and exploitative historical foundations of contemporary Artificial Intelligence and automation systems in the workplace.
- rise of temporary and insecure work is a result of social, economic, and political choices made by corporations and policymakers
- industrial revolution made workers all under one roof to be more organized, this in all introduced the wage system
- the second industrial revolution which began decades ago introduced the gig economy and collapsed secure-wage work, the last 40 years have seen a massive increase in insecure and temporary positions across all income levels
- short-term work causes little moral compact between employer and employees due to replace or frequent fire and hire

### Jathan Sadowski → data as capital
- data has become a fundamental form of capital and principle of contemporary economic life
- Amazonian era where Amazon acquired Whole Foods with a main purpose of gathering expansive surveillance information or monetization of data
- main value of Whole Foods come from the valuation of data was the true value. knowing how people shop or connect and track customers off-line and inline
- data collection is now the prime motivation for technological development where companies no longer profit-driven but data-driven as an investment
- led towards Amazon track their location, carts, and behavior all based on surveillance, data manufacturing
- data as capital
	1. profiling and targeting people → personalized advertising, differential pricing, and political messaging
	2. optimizing systems → increase efficiency, productivity, and achieve significant savings
	3. managing things → data functions as mobile, machine-readable form of knowledge that enhances the ability to control objects and people
	4. modeling probabilities → using extensive data and algorithms to make predictions
	5. building stuff → data is required to train and operate digital systems and machine learning algorithms
	6. growing the value of assets → smart technology make more adaptive and responsive

### Kate Crawford → ai takes over human work
- challenge the perception of ai and automation that takes over human work
- ai systems are deeply rooted in and reliant upon exploitation, surveillance, and micromanagement of human labor
- Amazon demonstrates the use of monitoring systems every second of shift through breaks, entry/exits, and inefficient working
- control over time and high surveillance, historically used to prisons or workers to be on task and efficiently working for maximum output at minimal cost
- ghost work and fake automation (fauxtomation) → ai systems rely heavily on invisible and exploitation of human effort
	- highly educated crowdworkers are paid below minimum wage to perform repetative digital tasks to train data. usually expected cheap frictionless completion of work usually slightly more demanding thatn using machines 
	- Mechanical Turk → human inside machine
- proprietary control of time → centralized power or TrueTime by Google
- Amazon workers work over “the rate” which is a core business model that controls the floor or base work imposed by workers