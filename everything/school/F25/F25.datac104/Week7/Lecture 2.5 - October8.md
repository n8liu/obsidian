
**Nathan Malkin** → the theory of Contextual Integrity (CI) as a necessary and superior model for defining privacy in the digital agehey fail to explain or analyze why many data practices are still perceived as privacy violations in complex sociotechnical systems. CI addresses this gap by defining privacy as the "appropriate flow" of personal information that conforms to legitimate, entrenched contextual norms. By providing a structured way to analyze flows based on five specific parameters
- basically sets a standard for privacy violations
### I. Defining Privacy and Its Historical Origins

Privacy is defined as a cluster of concepts, including freedom of thought, control over one’s body, and the private sphere. It is an ambiguous concept that is "diagnostic," meaning what one thinks about privacy reveals what one thinks about society.

**Historical Foundations:**

- **The Right to Be Let Alone:** The origin of the term "right to privacy" came from a law review by Justice Louis Brandeis in the mid-19th century, spurred by the emergence of an "information society" involving mass newspapers, photography, and private investigators. Brandeis defined it as the "right to be let alone, to have a private life free from public eyes". This early concept was mainly intended for middle-class, "respectable citizens".
- **Administrative State:** The rise of the administrative state involved collecting records of citizens' lives, such as social security numbers.
- **Modern Context:** Although today privacy law is linked to the 4th Amendment, the text itself does not mention privacy. The concept only entered common U.S. vocabulary in the 1960s and 1970s, following social upheavals like the FBI COINTELPRO domestic spying and the 1972 Watergate Scandal.

### II. The U.S. Regulatory Paradigm (1970s)

Government response to public concerns led to the development of the foundational U.S. approach to privacy, which was co-produced with late 20th-century concerns about computerized databases and government overreach.

- **Fair Information Practices (FIPs):** The key development was the **Privacy Act of 1974**, which applies FIPs (also called FIPPs) to U.S. Government systems. FIPs serve as an adaptable and extensible template, distilled into three main tenets: individual consent, security, and enforcement.
- **Sectoral Regulation:** Instead of an overall federal data privacy law for U.S.-based businesses, the U.S. uses sectoral regulation, regulating specific sectors to protect specific kinds of data or people. Examples include the Fair Credit Reporting Act of 1970, FERPA (student records), and HIPPA (health records).
- **Enforcement:** The Federal Trade Commission (FTC) holds the federal enforcement role for consumer privacy for businesses. Businesses largely rely on self-regulation and adhering to FTC guidelines and promises made to consumers. State laws, such as the California Consumer Privacy Act (CCPA), also exist.

### III. Core Concepts and Technical Challenges

- **Personally Identifiable Information (PII):** PII is a legal concept defining information that can be used on its own or with other information to identify, contact, or locate a single person. Protecting PII is a standard best practice.
- **De-identification vs. Re-identification:** De-identification is intended to prevent a person from being linked to information, but it is not foolproof. For instance, a high percentage of Americans could be uniquely identified by combining zip code, date of birth, and gender.
- **Differential Privacy:** This is a technical advance where privacy losses are mathematizable. It involves injecting random noise into data to prevent reidentification without compromising analytical usefulness (e.g., in U.S. census results or machine learning training datasets).

### IV. Limitations and New Concerns

The inherited privacy paradigm (focused on FIPs and PII) dramatically reduces what is considered privacy in life. The regulation of privacy is currently very limited.

**Criticisms of the Foundational Paradigm:**

- **Individual Focus:** The approach focuses heavily on individual control over personal data rather than collective impacts.
- **Cumulative Effects:** It relies on individuals to manage their data decisions moment-by-moment, ignoring the cumulative effects of data piling up from different places.
- **Ethical vs. Legal:** The framework implicitly encourages people to identify what is ethical solely with what is legal.

**New Concerns in the Datafied World:** New concerns stemming from the contingent nature of current privacy foundations include far-reaching data circulation, re-identification through dataset combinations, new modes of collection, increased ease of surveillance, algorithmic judgment/prediction, and data capitalism.