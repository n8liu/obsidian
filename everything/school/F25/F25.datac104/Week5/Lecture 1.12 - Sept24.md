### AI Narrative Templates and the Human Condition

The lecture identifies three primary narrative templates for how humanity might coexist with AI: AI dominating us, AI fusing with us (transhumanism), or AI becoming our companions. These stories are not just about technology; they are profound explorations of human existence, questioning the boundaries of what it means to be human and what threatens it. Rather than simply imagining what life with AI will look like, these narratives often function as a mirror, reflecting our anxieties and aspirations about the human condition itself, touching on issues like social inequality, violence, gender, consciousness, and the pursuit of a good life.

A key myth critiqued is that of Pygmalion, the sculptor who falls in love with his creation, a statue brought to life by a goddess. This foundational story of male creativity shaping a muted, subjected female is echoed in modern AI films like _Ex Machina_ and _Her_. Scholar Nina Begus argues this overemphasis on creating human-like AI limits our imagination and directs the technology's development. This myth also inspired the name for ELIZA, an early chatbot (1964-1967) designed to imitate human conversation, linking back to George Bernard Shaw's play _Pygmalion_, where a working-class woman is "trained" to speak like an aristocrat.

### The Framing of "Intelligence"

The very concept of "intelligence" in AI is shaped by these narratives. Alan Turing's influential "Turing Test" (1950) proposed that a machine can be considered to "think" if it can deceive a human into believing it is also human. This framed intelligence as disembodied linguistic imitation. This idea is part of a longer history of defining intelligence as something measurable and computational. Key definitions reinforce this:

- **John McCarthy**: "the science and engineering of making intelligent machines," where intelligence is "the computational part of the ability to achieve goals in the world".
- **OpenAI**: "a highly autonomous system that outperforms humans at most economically valuable work". These definitions raise the question of why this specific, computational version of "intelligence" has come to define what it means to be human in these discussions.

### The "Spear Narrative," Longtermism, and Existential Risk

Many dominant AI narratives are rooted in a specific vision of human history called the "spear narrative". Influenced by mid-century anthropology, this view posits that human evolution is driven by technology developed for violence. This is famously depicted in _2001: A Space Odyssey_, where an ape's bone weapon transforms into a spaceship, framing technological progress as a deterministic line from primitive tools to AI and the self-transcendence of the species.

This framing directly informs the powerful ideologies of longtermism and existential risk (X-risk) that are deeply interwoven with the AI community in Silicon Valley.

- **Existential Risk (X-risk)**: Promoted by figures like Nick Bostrom, this concept centers on the threat of Artificial General Intelligence (AGI) or superintelligence causing human extinction.
- **Longtermism**: Growing out of the Effective Altruism movement, longtermism applies utilitarian principles to rationalize philanthropy and long-term thinking. It argues that because the number of potential future humans is vast, ensuring their existence outweighs almost any present-day concern. The greatest threat to this future is human extinction, and the most likely cause is deemed to be AI. This justifies immense focus and resources on controlling AI's development to maximize "good" in the distant future.

These ideologies are nurtured in rationalist communities, symbolized by the "Lighthaven" house, owned by Lightcone Industries—a name referencing the desire to colonize the entire possible universe ("lightcone") to enact this vision of the future. The lecture notes that both the optimistic "boomers" and pessimistic "doomers" in the AI debate often share the same underlying assumptions and contribute to AI hype cycles.

### Transhumanism, Immortality, and Class Conflict

A central theme in these AI futures is transhumanism: the idea of controlling human evolution and transcending our biological limitations by merging with technology, particularly AI. This concept has roots in the work of eugenicist biologist Julian Huxley and is prevalent in Silicon Valley culture, as seen in interviews with figures like Peter Thiel.

This drive is often expressed as a desire to escape death, a powerful motif in AI narratives.

- Examples include tech CEO Bryan Johnson’s "Project Blueprint" to reverse his aging, the practice of cryonics (freezing one's body until AGI can upload their consciousness), the replicant Roy Batty's plea for "more life" in _Blade Runner_, and the depiction of eternal life in the cloud in _Black Mirror's_ "San Junipero" episode.
- The paradox is that this quest for immortality is often achieved through the symbolic "death of the human being" as we know it, representing a flight from the fundamental aspects of the human condition: mortality, embodiment, and change.

The lecture suggests these longevity narratives can be interpreted as allegories for class conflict. Drawing on theorist Fredric Jameson, it posits that the division between classes is represented by a differential in "life chances"—the ways in which poverty, dangerous work, and unemployment diminish life. In this light, the word "robot" itself is revealing, originating from the Czech "robota," meaning serf labor or drudgery. The rise of robots in fiction can thus be seen as an unconscious fear of labor uprisings.

### Key Takeaways

The lecture concludes that "AI" is not a single sociotechnical system but a form of futuring expressed through influential narrative templates. By examining these templates, we can see how AI serves as a powerful mirror for the human condition, reflecting our deepest concerns about social inequality, history, time, and mortality. Ultimately, ideologies like longtermism and transhumanism are attempts to escape death and the human condition, but paradoxically, they often end up imagining the death of the human itself.