# LECTURE 1 (1/20)
NPL is interdisciplinary → used in many majors

Turing Test → human vs computer can tell difference who wrote it

LLM → mainly performs well on trained data or sentiment analysis![[Screenshot 2026-01-28 at 3.08.49 PM.png]]![[Screenshot 2026-01-28 at 3.11.12 PM.png]]


# Lecture 2 (1/22)
Tokenization → break down sentences or words into basic units

Subtokenization → breaking words into smaller units (prefixes, suffixes, etc)

## Reading Unit 2
- Word Types: number of **distinct words** in a vocabulary
- Word Instances: total number of running words in a text (in other words **tokens**)
- Byte-Pair Encoding: algorithm that breaks down text into tokens
	- letter statistics → common letters pairings to predict the next letter
	- tokenized → add most frequent pairs (including spaces)
- Morphemes → the minimal meaning-bearing units in a language
- Types → unique instances
- Tokens → breakdown of sentences into word breaks

1. What is the difference between word types and word instances? You should be able to correctly count the number of word types and instances in a passage of text.
	- word types are total distinct or unique words and word instances are tokens

2. What are some examples of how defining what counts as a “word” is difficult, even in English? What makes tokenization in languages like Chinese and Japanese difficult?
	- words in english are difficult mainly due to words that are multiple words like “New York”, in other languages their is usually no breaks in sentences like spaces which incurs lots of ambiguity

3. What is a function word?
	- 

5. What is a subword, and how is it different from a "word"?

6. You should be able to use your recollection of the BPE algorithm to generate a BPE vocabulary given an input corpus (see algorithm in figure 2.6, along with discussion around it).

7. Regular expressions: you should be able to use regular expressions to match a pattern in an input text, including character disjunctions, optionality, wildcards and capturing groups.

8. How are regular expressions relevant to tokenization?

# Lecture 3 (1/27)
- 


## Reading Unit 5
- 

## QUIZ 1
- 

# Lecture 4
- 