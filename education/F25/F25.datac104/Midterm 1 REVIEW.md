Scott → trees

Benjamin → shirley cards

Eubanks → AFST

Brooks → countries

Bowker → South Africa

Keyes → FAT

Winner → bridges

Clayton → statistics and eugenics

Foucault → panopticon




## Week1

### Lecture 1.1 & Lecture 1.2 - Introduction and Making the Datafied World
- technologies have politics ← langdon winner
- technical artifacts embody social values
	- technology influences society

### **Langdon Winner** → Sociotechnical & Political (**Co-Production**) of a bridge
- technologies built with a motive in discrimination & politics
- ex bridge/overpass (**Performativity**)
	- the bridge (the technology) did not build inequality but was formed around it (the political)

## Week2

### Lecture 1.3 & Lecture 1.4- Making Data & Making Personal data
- Bay Area Air Quality (AQI) → simplified information not contextualized enough
- View from Above
	- abstract represented as a single data point
- View from Below
	- a lived personal experience, basically everything contextualized
- Classification → sorts and ranks people based on numerical score, turns people into data points of risk assessment (generally dehumanizing)
- Vulnerability: data travels between agencies and given to companies as a risk to their data and themselves
### **Ruha Benjamin** → coded exposure (New Jim Code/Shirley Cards)
- technologies either made black people invisible (camera color corrections) or hypervisible (surveillance cameras)
- New Jim Code: discriminatory designs encode inequity by explicitly amplifying racial hierarchies
	- Shirley Cards: which were standardized using the image of a white woman, leading to the routine underexposure of darker skin tones
- Fairness & Bias: inequality towards black people in technology that focused on white people
	- poor representation and mainly defaulted to white
- Sociotechnical Systems: Benjamin shows how racial ideologies (the social) are built into the very hardware and software of visual technologies (the technical) 
### **Geoffrey C. Bowker & Susan Leigh Star** → racial classification in South Africa
- South Africa classification was never neutral since they had four categories but people fell between the categories
	- resulted in arguments and reclassification into usually lower classes (misclassification)
- Classification: not a neutral act of sorting but a political act of creating and enforcing a brutal social order. It shows how classifications embed values and silence other points of view
- Sociotechnical Systems: involved laws (the social) and technologies of classification like passbooks, databases, and even crude "pencil tests" (the technical) that worked together to enforce racial segregation
- **Performativity**: being classified into a certain race determined where you could live, work, and who you could marry, thus creating the very racial hierarchy it purported to describe. The system's fictions transformed people's lives

## Week3
### Lecture 1.5 & Lecture 1.6 - Eugenics and Statistics
- co-production of the modern state, population, and statistics
- collecting population data → increase  their power through taxation, conscription, and management of population health → known as biopower
- “the average man” based on normal distribution which is a statistical project which is deeply influenced by eugenics and eugenic supremacists
- Co-production: central argument is that statistics and eugenics are co-produced
- Biopower: eugenics is a form of biopower, a state-directed project for better breeding
- Norming populations: “average man”
### **James C. Scott** → scientific forestry
- forest replaced by a single species of trees for harvesting
	- only cared about taxes/economy  did not consider environmental or global view before creating farms
- primary source for the concept of the **"administrative grid"** as an "intellectual filter"
	- only considered tunnel vision
### **Aubrey Clayton** → Eugenics
- **Francis Galton, Karl Pearson, and Ronald Fisher** → the development of statistics was co-produced with ulterior motives mainly surrounded a superior race or eugenics
	- people could not refute statistics because people had to understand it
- Co-production of Eugenics and Statistics: statistics developed with the answer of a superior race
- Eugenics (subclass of Biopower): better breeding by reproducing desirables races and removing undesirable races
- Concluded that statistics is objective and has no normal answer, co-produced but unrelated

### Lecture 1.7
- View from Above → global scale
	- picture thing as small as possible (usually a data point)
- Gapminder.org → case study
	- data visualizations can embed a specific narrative since missing
	- developing countries are seen as moving towards American and European countries as they are “behind” according to the more developed countries
- Biopower: family planning program
- Representation: world through data brings repsentational harm to certain populations
### **Andrew Brooks** → HDI (Human Development Index)
- rank countries on economic growth and status
	- does not consider historical and immigration contributions
	- colonialism or exploitation of the poor mainly contributed to more successful countries
- **Narratives**: global data visualizations like Gapminder, suggests a linear path to progress modeled on the West
	- basically states that in order to grow as a country follow these steps (incorrect)
- Global Data & View from Above: The HDI is an example of **global data** that provides a **"view from above,"** creating a single, abstract ranking of all countries
	- does not consider outside factors
- Relationality: Brooks' call for a "relational comparison" mirrors the course concept of relationality in data. Just as personal data about one person is always entangled with data about others, the development status of one country is entangled with the status of others through global flows of capital, resources, and people

## Week4

### Lecture 1.8 & Lecture 1.9 - Automated Decision-Making (ADM)
- algorithmic fairness and ADM (COMPAS)
	- risk-assessment tool had errors rates for Black and white defendants
	- fairness is contextual and contested political concept
	- fixing the algorithm often fails to address baised in criminal justice system
	- AFST demonstrates the danger and violation of due process and performativity where high-rosk scores become significantly more useful than lower scores
		- hurts more unfortunate people
- COMPAS → risk-assessment tool
- Fairness: COMPAS demonstrates that mathematically impossible to be complete fairness.
### **Os Keyes** → Fairness, Accountability, and Transparency (FAT) framework
- algorithm to turn old people into mulch (fertilizer or food)
	- using algorithm to identify elderly people by using facial recognition and data points (misclassifies)
	- algorithm improves by using
		1. Fairness: add more data points
		2. Accountability: 10-second appeal drone
		3. Transparency: public signage and website to import own data
	- algorithm still fails
- Fairness: using data points is not fair but should consider contextual and contested data points
### **Virginia Eubanks** → AFST (Allegheny Family Screening Tool)
- tool to predict child neglect and abuse
- deeply flawed and makes poor judgement against mainly the poor
	- unproportionally targets the poor due to being only access to public data not private data from the rich
- ADM (Automated Decision-Making): using a range of context to decide information based on data, realistically missed out on a bunch of contextual information
- Fairness (algorithmic bias): AFST had significant bias in both racial and class. AFST trained on historical data that targeted black families to be refer more often creating an inequality between blacks and whites**

### Lecture 1.10 - Rules & Risk
- automated decision-making (ADM), arguing that risk assessment, fairness, and modern liberalism are co-produced
- This industry championed the concept of "actuarial fairness": the idea that it is only fair for individuals to pay for their own risk, not for the risks of others
- It governs people not as citizens with rights, but as "human capital" or "risk portfolios," and its moral framework of "actuarial fairness" erodes the basis for redistributive politics by framing misfortune as a personal failure
- Risk Pools:  a group of individuals who are classified together for the purpose of managing, calculating, and pricing risk
### **Michel Foucault** → Panopticon (**Performativity**)
- central tower that can oversee all cells around in a circle, the inmates can see the tower and outside but the sun shines so that the inmates cannot see whos in the tower
- his creates a state of "conscious and permanent visibility that assures the automatic functioning of **power**"
	- the inmates know they are being watched but cannot see when or who (similar to social media)
	- **Power** is not just a physical force but also represented as self-discipline
- Biopower: form of power that manages populations by fostering and controlling life

## what to study?
1. Lecture
2. Readings
3. **HCE toolkit**

Tools
- Vulnerability
- Representation
- Classification
- Power
- Identity/Positionality

Key Terms
- abstraction
- circulation
- relationality
- representational harm

Case Studies
- corodinated entry system
- direct-to-consumer (DTC) DNA testing

Recommendations
- connect last names to readings


HCE Tools (define them)
- **Agency**: is the ability or capacity to act or exert power. Technology informs the way in which people both perceive and exercise their capacity to exert some degree of control over the sociotechnical relations in which they are enmeshed.
	- Algorithmic decision-making (COMPAS, Gig economy laborers)
	- Real-time interplay of human and mechanical agency (autonomous vehicles, pilots)
	- Patients tracking their health through data apps and devices
	- Google Walkout, unionization
	- Disruptive innovation and the tech entrepreneur agent
- **Classification**: mplicit and explicit social organization of beings and knowledge into discrete categories governed by identifiable principles. Societies produce knowledge and do work (e.g. with technologies) by sorting, ordering, and classifying phenomena in the world. Classification systems inform social order and vice versa.
	- Air Quality Data
	- Racial Classification in Apartheid South Africa
	- Risk and vulnerability assessment algorithms (VI-SPDAT, AFST)
- **Co-production**: Technology and society are mutually constitutive, or, in other words, they depend on one another for the forms they assume: technology makes society what it is, and society makes technology what it is. Or, “Technology is co-produced with society.”
	- Ideas of privacy co-produced with social media platforms
	- Statistical tools are co-produced with the formation of the nation-state
	- Ethical codes are co-produced with professions
	- Labor conditions in the datafied world are co-produced with technologies of surveillance
- **Identity/Positionality**: Life-shaping and socially conditioned aspects of selfhood, such as gender, race, class, disability status, income, immigration status. Identity is not only about how you see yourself but also how society sees and treats you (positionality). Identity is co-produced with technology.
	- Disparate impact of algorithms on different identities (facial recognition technologies; predictive policing)
	- Social media activism as a component in the civil rights struggle for the recognition and rights for people with particular identities
	- Self-tracking technologies built around particular concept of identity (self-aware, efficient)
- **Labor**: The socially organized use of human bodies and lifetime to reproduce the material conditions of human life. Asking about labor helps us look to sociotechnical processes of production, working conditions, and how labor is differentially valorized, exploited, and structured in various historical and sociotechnical contexts. Labor is also a social agent - “organized labor” can be a political force that shapes the conditions under which labor takes place
	- "Gig-economy" and platform-based labor
	- Invisible labor
	- Amazon warehouse
	- Narratives of robotics and the automation of certain types of labor
- **Narrative**: Stories in time that express and explain things that matter to people: who they are, how the world is, how things work, what needs to be done, what futures are possible, desirable, or inevitable. Technology shapes and is shaped by narratives that are at-large in society. Narratives can come to feel natural, but always need to be questioned
- **Performativity**: The way that actions that describe the world (language, concepts, metaphors, models, classification systems, measurement systems, predictions, automated decision-making systems) can shape and even bring into being the very phenomena they set out to describe.
	- Racial classification systems
	- Algorithmic Self
	- Quetelet’s “Average Man”
	- Performance rating/scoring systems
	- Surveillance capitalism, A/B testing and behaviorism
	- Predictive Policing (urban surveillance; Allegheny Family Screening Tool)
- **Power**: The asymmetric capacity of an agent to structure or alter the behavior and decisions of other agents, populations, or systems. Technological (computational) power is intertwined with political power.
	- Robert Moses's Overpasses
	- Population statistics, biopower, and eugenics 
	- Panopticon, Surveillance and predictive policing
- **Representation**: The way in which one thing is made to "stand for" another. Technologies create representations of people and of social/natural phenomena that do particular work in the world and acquire a life of their own, refiguring the identity and agency of the represented person/phenomena.
	- Pima Indian Diabetes Database
	- Ownership of genetic information
	- FSM and student protests against being treated as "information to be processed”
	- Technologies of the census and political representation
	- Measuring climate change and exercise of citizenship
- **Sociotechnical Systems**: A system in which the actions of people and technologies are intertwined such that it’s not possible to just isolate the “technical part” and deal with on its own. Large and highly complex sociotechnical systems distribute risks and responsibilities widely and unevenly, and are difficult to regulate. When they fail it is often difficult or even impossible to identify a single human or mechanical cause.
	- Self-driving cars; nuclear power plants; airplanes; streetlights
	- Risk society
	- Social media platforms and the public sphere
	- Internet-of-things, Smart city
- **Vulernability**: The condition of being exposed to others and to the risk of injury. Vulnerability is central to personhood and the human condition. It is part of every social relationship, and is at the heart of ethics. Vulnerability is differentially distributed in society: it varies by positionality (race, class, gender, immigration, disability…). Technology shapes who becomes vulnerable and how

Concept Mapping
- start with concept / tools / case-studies focus on synthesizing or connecting
![[Screenshot 2025-09-19 at 11.34.58 AM.png]]

- Review Course Materials 
	- Lecture Content
		- Claims, key terms, and case studies 
		- Pay close attention to the takeaways that frame these materials 
		- Always have tools in the back of your mind 
		- Focus on meanings in context. Try to avoid looking up content on Wikipedia or elsewhere. 
		- Circulation: when data is made in a certain context, data is inevitably circulated and moved into contexts where it is decontextualized and taken out of its original context 
	- Readings
		- Key claims, concepts, and evidence (such as case studies of real world examples) 
		- What are the important arguments of readings and how they relate to this class?
		- In bcourses in assignments can go into warmup assignments to look at guiding questions for reading
	- HCE Tools
		- Understand what they mean and more importantly how to apply them 
- Build a concept map
	- Once you have compiled the course materials, focus on synthesizing what you have.
	- Coordinated Entry System 
		- For the unhoused in LA
		- Generate a vulnerability score using personal data that is somewhat ambiguous
